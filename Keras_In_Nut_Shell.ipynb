{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intent to use this jupyter for myself, quick refresher / class-notes for course material studied for  Neural Networks from Udacity [ & not to reproduce any material as such ..]\n",
    "\n",
    "This guide DOES NOT go in depth explaining fundamentals, & may appear be in arbitraty sequence to follow, as it is aligned to class labs. One should go through proper course material prior using this guide. I highly recommend Udacity nanodegree course(s) as right medium to learn this subject.\n",
    "\n",
    "Content Credit: Udacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the simplest example. In this quiz you will build a simple multi-layer feedforward neural network to solve the XOR problem.\n",
    "\n",
    "1. Set the first layer to a Dense() layer with an output width of 8 nodes and the input_dim set to the size of the training samples (in this case 2).\n",
    "2. Add a tanh activation function.\n",
    "3. Set the output layer width to 1, since the output has only two classes. (We can use 0 for one class an 1 for the other)\n",
    "4. Use a sigmoid activation function after the output layer.\n",
    "5. Run the model for 50 epochs. <br>\n",
    "\n",
    "This should give you an accuracy of 50%. That's ok, but certainly not great. Out of 4 input points, we're correctly classifying only 2 of them. Let's try to change some parameters around to improve. For example, you can increase the number of epochs. You'll pass this quiz if you get 75% accuracy. Can you reach 100%?\n",
    "\n",
    "To get started, review the Keras documentation about models and layers. The Keras example of a Multi-Layer Perceptron (https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py) network is similar to what you need to do here. Use that as a guide, but keep in mind that there will be a number of differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anmehra/Desktop/Anconda_Py2.7/anaconda/envs/dlnd/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TensorFlow 1.0.0; use tf.python_io in later versions\n",
    "#tf.python.control_flow_ops = tf\n",
    "tf.python_io = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Our data\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]]).astype('float32')\n",
    "y = np.array([[0],[1],[1],[0]]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2) (4, 1)\n"
     ]
    }
   ],
   "source": [
    "print (X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial Setup for Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 8)                 24        \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4/4 [==============================] - 0s 20ms/step\n",
      "\n",
      "Accuracy:  1.0\n",
      "\n",
      "Predictions:\n",
      "[[0.2963529 ]\n",
      " [0.6396637 ]\n",
      " [0.64616007]\n",
      " [0.34992346]]\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "xor_model = Sequential()\n",
    "\n",
    "# Add required layers\n",
    "# xor.add()\n",
    "\n",
    "# 1st Layer (layer_1 Hidden Layer) - Add an input layer of 8 nodes with the same input shape as\n",
    "# the training samples in X\n",
    "xor_model.add(Dense(8, input_dim=X.shape[1]))\n",
    "\n",
    "# Add a tanh activation layer to the output of layer_1 i.e. hidden layer above\n",
    "xor_model.add(Activation('tanh'))\n",
    "\n",
    "# 2nd Layer (Output Layer) - Add a fully connected output layer\n",
    "xor_model.add(Dense(1))\n",
    "\n",
    "# Add a sigmoid activation layer to Output Layer\n",
    "xor_model.add(Activation('sigmoid'))\n",
    "     \n",
    "# Specify loss as \"binary_crossentropy\", optimizer as \"adam\",\n",
    "# and add the accuracy metric\n",
    "# xor.compile()\n",
    "xor_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics = [\"accuracy\"])\n",
    "\n",
    "# Uncomment this line to print the model architecture\n",
    "xor_model.summary()\n",
    "\n",
    "# Fitting the model\n",
    "history = xor_model.fit(X, y, epochs=500, verbose=0)\n",
    "\n",
    "# Scoring the model\n",
    "score = xor_model.evaluate(X, y)\n",
    "print(\"\\nAccuracy: \", score[-1])\n",
    "\n",
    "# Checking the predictions\n",
    "print(\"\\nPredictions:\")\n",
    "print(xor_model.predict_proba(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Labs to go in depth showing 2 different examples ..\n",
    "\n",
    "1. Student Admission : https://github.com/anshoomehra/udacity-deep-learning/tree/master/student-admissions-keras\n",
    "\n",
    "2. IMDB Reviews Sentiment Analysis : https://github.com/anshoomehra/udacity-deep-learning/tree/master/IMDB-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
